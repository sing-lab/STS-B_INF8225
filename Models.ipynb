{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running all models (BERT based models can be run and used in the BERT_based_models notebook)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Program Files\\Python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from loader import loader_train, loader_test, train_validation_split\n",
    "from transforms import MinEditDistance, Vectorizer, LemmaTransform, FuncTransform, Mixor, \\\n",
    "                        SynonymTransform, POSTransform, BaseTransform, ProcessingVocab, \\\n",
    "                        EmbeddingTransform, TokenTransform, EncoderTransform, BERTProcessing\n",
    "from models import BowModel, CosineSimilarity, build_matrix, SiameseLSTM, BERTModel, MLPEstimator\n",
    "from evaluation import evaluate_model, spearman_measure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import joblib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX, y = loader_train()\n",
    "dfX_test = loader_test()\n",
    "vocab = ProcessingVocab(dfX).voc()\n",
    "fname=\"data/glove-wiki-gigaword-300.txt\"\n",
    "df_embeddings = build_matrix(vocab=vocab, fname=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model_counts = BowModel(ponderation='count') # Bag of words using simple tokenization and 'counts' weights\n",
    "bow_model_tfidf = BowModel(ponderation='tfidf') # Bag of words using simple tokenization and 'TFIDF' weights\n",
    "POSModel = make_pipeline(POSTransform(tags_only=True, join_labels=True), # Compare POS tags\n",
    "                         Vectorizer(ponderation='tfidf'), \n",
    "                         CosineSimilarity())\n",
    "synonyms_model_counts = make_pipeline(SynonymTransform(), # Process data with synonyms and 'counts' weights\n",
    "                                                                     Vectorizer(ponderation='count'), \n",
    "                                                                     CosineSimilarity())\n",
    "synonyms_model_tfidf = make_pipeline(SynonymTransform(), # Process data with synonyms and 'TFIDF' weights\n",
    "                                     Vectorizer(ponderation='tfidf'), \n",
    "                                     CosineSimilarity())\n",
    "lemmas_model_counts = make_pipeline(LemmaTransform(), # Process data with lemmas and 'counts' weights\n",
    "                                    Vectorizer(ponderation='count'), \n",
    "                                    CosineSimilarity())\n",
    "lemmas_model_tfidf = make_pipeline(LemmaTransform(), # Process data with lemmas and 'TFIDF' weights\n",
    "                                   Vectorizer(ponderation='tfidf'), \n",
    "                                   CosineSimilarity())\n",
    "inverse_med_model = make_pipeline(MinEditDistance(), # Compute Min-Edit-Distance and inverse it to get score between 0 and 1\n",
    "                                    FuncTransform(lambda x:1/(1+np.sqrt(x))))\n",
    "embeddings_model = make_pipeline(TokenTransform(), EmbeddingTransform(method=sum), # Use dense vectors from Glove embeddings\n",
    "                                          CosineSimilarity())\n",
    "model_MLP = make_pipeline(Vectorizer(ponderation='tfidf'), Mixor(method='sum'), # Use 'TFIDF' preprocessing and Perceptron as estimator\n",
    "                          TruncatedSVD(n_components=1000), MLPEstimator())\n",
    "model_LSTM = make_pipeline(TokenTransform(), # Use Glove embeddings and siamese bidirectional LSTM to get sentence vectors\n",
    "                           EncoderTransform(vocab=vocab, l_seq=10), \n",
    "                           SiameseLSTM(df_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLP.fit(dfX_train, y_train) # Train Multi-Layer-Perceptron\n",
    "model_LSTM.fit(dfX_train, y_train) # Train LSTM mdoel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bow_counts = bow_model_counts.predict(dfX_test)\n",
    "y_bow_tfidf = bow_model_tfidf.predict(dfX_test)\n",
    "y_POS = POSModel.predict(dfX_test)\n",
    "y_synonyms_counts = synonyms_model_counts.predict(dfX_test)\n",
    "y_synonyms_tfidf = synonyms_model_tfidf.predict(dfX_test)\n",
    "y_lemmas_counts = lemmas_model_counts.predict(dfX_test)\n",
    "y_lemmas_tfidf = lemmas_model_tfidf.predict(dfX_test)\n",
    "y_inverse_med = inverse_med_model.transform(dfX_test)\n",
    "y_embeddings = embeddings_model.predict(dfX_test)\n",
    "y_MLP_test = model_MLP.predict(dfX_test)\n",
    "y_LSTM_test = model_LSTM.predict(dfX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Models.ipynb to html\n",
      "[NbConvertApp] Writing 293068 bytes to Models.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html Models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
